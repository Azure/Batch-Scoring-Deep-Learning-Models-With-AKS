{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Style Transfer on AKS\n",
    "\n",
    "Now that the AKS cluster is up, we need to deploy our __flask app__ and __scoring app__ onto it.\n",
    "\n",
    "To do so, we'll do the following:\n",
    "1. Build our __flask app__ and __scoring app__ push it to Dockerhub\n",
    "2. Create our dot-yaml files for each of these apps (these dot-yaml files will need to have the proper configuration for the pods to use blobfuse to access our blob storage container). We should end up creating: `flask_app_deployment.json` and `scoring_app_deployment.json`\n",
    "3. Use `kubectl` to make these deployments to our AKS cluster\n",
    "4. Expose the __flask app__ REST endpoint so that it can be accessed externally\n",
    "\n",
    "### Kubernetes Deployment\n",
    "In this notebook, we will deploy our __flask app__ and __scoring app__ on the kubernetes cluster. Since the __flask app__ does not require heavy computation, we will deploy it on one node and reserve the remaining nodes for the __scoring app__ as it will perform the parallel computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import set_key, get_key, find_dotenv, load_dotenv\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Scoring App Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scoring_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_app/requirements.txt\n",
    "azure==4.0.0\n",
    "torch==0.4.1\n",
    "torchvision==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scoring_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile scoring_app/Dockerfile\n",
    "\n",
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        build-essential \\\n",
    "        ca-certificates \\\n",
    "        cmake \\\n",
    "        curl \\\n",
    "        git \\\n",
    "        nginx \\\n",
    "        supervisor \\\n",
    "        wget && \\\n",
    "        rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "ENV PYTHON_VERSION=3.6\n",
    "RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  && \\\n",
    "    chmod +x ~/miniconda.sh && \\\n",
    "    ~/miniconda.sh -b -p /opt/conda && \\\n",
    "    rm ~/miniconda.sh && \\\n",
    "    /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION && \\\n",
    "    /opt/conda/bin/conda clean -ya\n",
    "ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
    "ENV PYTHONPATH /code/:$PYTHONPATH\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD process_images_from_queue.py /app\n",
    "ADD style_transfer.py /app\n",
    "ADD main.py /app\n",
    "ADD util.py /app\n",
    "ADD requirements.txt /app\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  43.52kB\n",
      "Step 1/17 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> f4f6aaaaa057\n",
      "Step 2/17 : RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
      " ---> Using cache\n",
      " ---> 4196af2ba86e\n",
      "Step 3/17 : RUN apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         cmake         curl         git         nginx         supervisor         wget &&         rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 8ddcde9d280a\n",
      "Step 4/17 : ENV PYTHON_VERSION=3.6\n",
      " ---> Using cache\n",
      " ---> 5a047de1f83a\n",
      "Step 5/17 : RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  &&     chmod +x ~/miniconda.sh &&     ~/miniconda.sh -b -p /opt/conda &&     rm ~/miniconda.sh &&     /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION &&     /opt/conda/bin/conda clean -ya\n",
      " ---> Using cache\n",
      " ---> 42fd602eabaa\n",
      "Step 6/17 : ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> e15ad65c7c32\n",
      "Step 7/17 : ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
      " ---> Using cache\n",
      " ---> 2281999563de\n",
      "Step 8/17 : ENV PYTHONPATH /code/:$PYTHONPATH\n",
      " ---> Using cache\n",
      " ---> e73919aaabd9\n",
      "Step 9/17 : RUN mkdir /app\n",
      " ---> Using cache\n",
      " ---> a586b032becf\n",
      "Step 10/17 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 379f3f867f7a\n",
      "Step 11/17 : ADD process_images_from_queue.py /app\n",
      " ---> Using cache\n",
      " ---> b5e1255d5fa6\n",
      "Step 12/17 : ADD style_transfer.py /app\n",
      " ---> Using cache\n",
      " ---> 0ae2e350f9f9\n",
      "Step 13/17 : ADD main.py /app\n",
      " ---> Using cache\n",
      " ---> 1965d8e0206f\n",
      "Step 14/17 : ADD util.py /app\n",
      " ---> Using cache\n",
      " ---> fe49b449e922\n",
      "Step 15/17 : ADD requirements.txt /app\n",
      " ---> Using cache\n",
      " ---> ed86e95d0a86\n",
      "Step 16/17 : RUN pip install --no-cache-dir -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 9da3fe0d72bd\n",
      "Step 17/17 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> 7d8c0cc0c25e\n",
      "Successfully built 7d8c0cc0c25e\n",
      "Successfully tagged batchscoringdl_scoring_app:latest\n"
     ]
    }
   ],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"SCORING_IMAGE\")} scoring_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"SCORING_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/jiata/batchscoringdl_scoring_app]\n",
      "\n",
      "\u001b[1B506c02a5: Preparing \n",
      "\u001b[1B997681f0: Preparing \n",
      "\u001b[1B27fe773a: Preparing \n",
      "\u001b[1B9cf2b9f2: Preparing \n",
      "\u001b[1B6063fec7: Preparing \n",
      "\u001b[1B2632d196: Preparing \n",
      "\u001b[1B8452f77e: Preparing \n",
      "\u001b[1Baad0d176: Preparing \n",
      "\u001b[1Bff05626e: Preparing \n",
      "\u001b[1B9048222b: Preparing \n",
      "\u001b[1Bf7dc85a1: Preparing \n",
      "\u001b[1B2df89268: Preparing \n",
      "\u001b[1Bd8f0884d: Preparing \n",
      "\u001b[1B87fdb58c: Preparing \n",
      "\u001b[1B8fb03d12: Preparing \n",
      "\u001b[1B843615e2: Preparing \n",
      "\u001b[1Ba8049aa6: Preparing \n",
      "\u001b[1B9c0f8a0b: Preparing \n",
      "\u001b[12Bad0d176: Waiting g \n",
      "\u001b[1B91f0ffec: Layer already exists K\u001b[16A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[9A\u001b[1K\u001b[K\u001b[5A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[Klatest: digest: sha256:ba89b4f436d2b428a83afd40a2186db391958b2f5524cde7cf28c166478dc7f1 size: 4507\n"
     ]
    }
   ],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Flask App Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our Dockerfile and save it to the directory, `flask_app/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flask_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile flask_app/Dockerfile\n",
    "\n",
    "FROM continuumio/miniconda3\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD add_images_to_queue.py /app\n",
    "ADD preprocess.py /app\n",
    "ADD postprocess.py /app\n",
    "ADD util.py /app\n",
    "ADD main.py /app\n",
    "\n",
    "# RUN conda install -c anaconda ffmpeg\n",
    "RUN conda install -c conda-forge -y ffmpeg\n",
    "RUN pip install azure\n",
    "RUN pip install flask\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  37.38kB\n",
      "Step 1/12 : FROM continuumio/miniconda3\n",
      " ---> d3c252f8727b\n",
      "Step 2/12 : RUN mkdir /app\n",
      " ---> Using cache\n",
      " ---> 3d09918b3c53\n",
      "Step 3/12 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> cdb65a76c343\n",
      "Step 4/12 : ADD add_images_to_queue.py /app\n",
      " ---> Using cache\n",
      " ---> 7c1787f853f4\n",
      "Step 5/12 : ADD preprocess.py /app\n",
      " ---> Using cache\n",
      " ---> 71901a55c05e\n",
      "Step 6/12 : ADD postprocess.py /app\n",
      " ---> Using cache\n",
      " ---> 3d38f2424ba4\n",
      "Step 7/12 : ADD util.py /app\n",
      " ---> Using cache\n",
      " ---> 0ef50f3ff91c\n",
      "Step 8/12 : ADD main.py /app\n",
      " ---> Using cache\n",
      " ---> 588ba5789458\n",
      "Step 9/12 : RUN conda install -c conda-forge -y ffmpeg\n",
      " ---> Using cache\n",
      " ---> 82012ba47c91\n",
      "Step 10/12 : RUN pip install azure\n",
      " ---> Using cache\n",
      " ---> 6c815240fb6b\n",
      "Step 11/12 : RUN pip install flask\n",
      " ---> Using cache\n",
      " ---> fe557a4f8a97\n",
      "Step 12/12 : CMD [\"python\", \"main.py\"]\n",
      " ---> Using cache\n",
      " ---> 56c9a40ea04f\n",
      "Successfully built 56c9a40ea04f\n",
      "Successfully tagged batchscoringdl_flask_app:latest\n"
     ]
    }
   ],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"FLASK_IMAGE\")} flask_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"FLASK_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/jiata/batchscoringdl_flask_app]\n",
      "\n",
      "\u001b[1B111a8365: Preparing \n",
      "\u001b[1B6e57c8c0: Preparing \n",
      "\u001b[1B793ec12d: Preparing \n",
      "\u001b[1B04eb0d91: Preparing \n",
      "\u001b[1Bdec93638: Preparing \n",
      "\u001b[1B2fb3d239: Preparing \n",
      "\u001b[1B5a465adc: Preparing \n",
      "\u001b[1B0c665bf2: Preparing \n",
      "\u001b[1B59854246: Preparing \n",
      "\u001b[1Bb5c98f73: Preparing \n",
      "\u001b[1B31f7d329: Preparing \n",
      "\u001b[1Bcc4bbc9d: Preparing \n",
      "\u001b[1Bae060f2d: Preparing \n",
      "\u001b[1Bf0b6fef8: Layer already exists \u001b[8A\u001b[1K\u001b[K\u001b[4A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[Klatest: digest: sha256:3c58467c4e4f78ec29332192d27e3776a7f2022a72e063f20b242217665c8cd1 size: 3248\n"
     ]
    }
   ],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our Flask App and Scoring App deployments on AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deploy both our aci and aks docker images to the AKS cluster. Since we'll need to set up our gpu and drivers and blobfuse mount point for both deployments, we'll set these up first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_mounts = [\n",
    "    {\"name\": \"nvidia\", \"mountPath\": \"/usr/local/nvidia\"},\n",
    "    {\"name\": \"blob\", \"mountPath\": get_key(env_path, \"MOUNT_DIR\")},\n",
    "]\n",
    "\n",
    "resources = {\n",
    "    \"requests\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "    \"limits\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "}\n",
    "\n",
    "volumes = [\n",
    "    {\"name\": \"nvidia\", \"hostPath\": {\"path\": \"/usr/local/nvidia\"}},\n",
    "    {\n",
    "        \"name\": \"blob\",\n",
    "        \"flexVolume\": {\n",
    "            \"driver\": \"azure/blobfuse\",\n",
    "            \"readOnly\": False,\n",
    "            \"secretRef\": {\"name\": \"blobfusecreds\"},\n",
    "            \"options\": {\n",
    "                \"container\": get_key(env_path, \"STORAGE_CONTAINER_NAME\"),\n",
    "                \"tmppath\": \"/tmp/blobfuse\",\n",
    "                \"mountoptions\": \"--file-cache-timeout-in-seconds=120 --use-https=true\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "env = [\n",
    "    {\n",
    "        \"name\": \"MOUNT_DIR\", \n",
    "        \"value\": get_key(env_path, \"MOUNT_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LB_LIBRARY_PATH\",\n",
    "        \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DP_DISABLE_HEALTHCHECKS\", \n",
    "        \"value\": \"xids\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"STORAGE_MODEL_DIR\",\n",
    "        \"value\": get_key(env_path, \"STORAGE_MODEL_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SUBSCRIPTION_ID\",\n",
    "        \"value\": get_key(env_path, \"SUBSCRIPTION_ID\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RESOURCE_GROUP\",\n",
    "        \"value\": get_key(env_path, \"RESOURCE_GROUP\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"REGION\",\n",
    "        \"value\": get_key(env_path, \"REGION\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_NAME\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_NAME\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_VALUE\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_VALUE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_NAMESPACE\",\n",
    "        \"value\": get_key(env_path, \"SB_NAMESPACE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_QUEUE\", \n",
    "        \"value\": get_key(env_path, \"SB_QUEUE\")\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the aks deployment and save it to a `scoring_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"scoring-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"dequeue_messages_and_apply_style_transfer\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": int(get_key(env_path, \"NODE_COUNT\")) - 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"scoring-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"scoring-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 433\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"scoring_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(scoring_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `scoring_app_deployment.json` we created, create our deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/scoring-app created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f scoring_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the flask app deployment and save it to a `flask_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flask_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"flask-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"pre_and_post_processing_and_queue_images\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"flask-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"flask-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 8080\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"flask_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(flask_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `flask_app_deployment.json` we created, create our flask app deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/flask-app created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f flask_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the state of the pods by running the command: `kubectl get pods`. When the deployment is done, the results may look as follows:\n",
    "```bash\n",
    "NAME                           READY   STATUS              RESTARTS   AGE\n",
    "flask-app-6db66c97ff-x8rq4     1/1     Running             0          78s\n",
    "scoring-app-846dd6bc79-5nm5b   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-6qc6k   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-8gtsv   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-hjsfc   1/1     Running             0          73s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expose the flask-app in the kubernetes cluster. This will open a public endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/flask-app exposed\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl expose deployment flask-app --type=\"LoadBalancer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `!watch kubectl get services` and wait until the external ip goes from pending to being realized. It can take some time.\n",
    "\n",
    "NOTE: If the following command is run without the external ip being realized, an error will be thrown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_ip = !kubectl get services -o=jsonpath={.items[*].status.loadBalancer.ingress[0].ip}\n",
    "external_ip = external_ip[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll use the `external_ip` later on, save it to the dot-env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "strip_out"
    ]
   },
   "outputs": [],
   "source": [
    "set_key(env_path, \"AKS_EXTERNAL_IP\", external_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that the deployment works end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the name of the new test video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video_name = \"aks_test_orangutan.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy the old `orangutan.mp4` video but named with the `<new_video_name>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/orangutan.mp4 data/{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `curl` to hit the endpoint of the kubernetes cluster we just deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing aks_test_orangutan.mp4 in background...\r\n"
     ]
    }
   ],
   "source": [
    "!curl {external_ip}\":8080/process?video_name=\"{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect your kubernetes cluster to see that the process is running. You can use the commands below to do so. Alternatively, you can also inspect the blob storage container to see that the images are being created.\n",
    "\n",
    "When the video completes, you can play the video file directly from your mounted blob container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"data/aks_test_orangutan/aks_test_orangutan_processed.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Kubectl usage\n",
    "You can use kubectl to perform basic monitoring. Use the following commands:\n",
    "```bash\n",
    "# monitor pods\n",
    "!kubectl get pods\n",
    "\n",
    "# print logs from a pod (<pod-name> can be found when calling 'get pods')\n",
    "!kubectl logs <pod-name>\n",
    "\n",
    "# check all services running on the cluster\n",
    "!kubectl get services\n",
    "\n",
    "# delete a service\n",
    "!kubectl delete services <service-name>\n",
    "\n",
    "# delete a deployment\n",
    "!kubectl delete -f scoring_app_deployment.json\n",
    "!kubectl delete -f flask_app_deployment.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor in kubernetes dashboard\n",
    "You can use the Kubernetes dashboard to monitor the cluster using the following commands:\n",
    "\n",
    "```bash\n",
    "# use the kube_dashboard_access.yaml to create a deployment\n",
    "!kubectl create -f kube_dashboard_access.yaml\n",
    "\n",
    "# use this command to browse\n",
    "!az aks browse -n {get_key(env_path, \"AKS_CLUSTER\")} -g {get_key(env_path, \"RESOURCE_GROUP\")}\n",
    "```\n",
    "\n",
    "If you're not able to access the dashboard, follow the instructions [here](https://blog.tekspace.io/kubernetes-dashboard-remote-access/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional commands for AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale your AKS cluster:\n",
    "\n",
    "```bash \n",
    "!az aks scale \\\n",
    "    --name {get_key(env_path, \"AKS_CLUSTER\")} \\\n",
    "    --resource-group {get_key(env_path, \"RESOURCE_GROUP\")} \\\n",
    "    --node-count 10\n",
    "```\n",
    "\n",
    "Scale your deployment:\n",
    "```bash\n",
    "!kubectl scale deployment.apps/aks-app --replicas=10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to the next [notebook](/notebooks/05_deploy_logic_app.ipynb)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:batchscoringdl]",
   "language": "python",
   "name": "conda-env-batchscoringdl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
