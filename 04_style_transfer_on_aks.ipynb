{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Style Transfer on AKS\n",
    "\n",
    "Now that the AKS cluster is up, we need to deploy our __flask app__ and __scoring app__ onto it.\n",
    "\n",
    "To do so, we'll do the following:\n",
    "1. Build our __flask app__ and __scoring app__ push it to Dockerhub\n",
    "2. Create our dot-yaml files for each of these apps (these dot-yaml files will need to have the proper configuration for the pods to use blobfuse to access our blob storage container). We should end up creating: `flask_app_deployment.json` and `scoring_app_deployment.json`\n",
    "3. Use `kubectl` to make these deployments to our AKS cluster\n",
    "4. Expose the __flask app__ REST endpoint so that it can be accessed externally\n",
    "\n",
    "### Kubernetes Deployment\n",
    "In this notebook, we will deploy our __flask app__ and __scoring app__ on the kubernetes cluster. Since the __flask app__ does not require heavy computation, we will deploy it on one node and reserve the remaining nodes for the __scoring app__ as it will perform the parallel computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import set_key, get_key, find_dotenv, load_dotenv\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)\n",
    "load_dotenv(env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Scoring App Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scoring_app/requirements.txt\n",
    "azure==4.0.0\n",
    "torch==0.4.1\n",
    "torchvision==0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scoring_app/Dockerfile\n",
    "\n",
    "FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
    "\n",
    "RUN echo \"deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /\" > /etc/apt/sources.list.d/nvidia-ml.list\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        build-essential \\\n",
    "        ca-certificates \\\n",
    "        cmake \\\n",
    "        curl \\\n",
    "        git \\\n",
    "        nginx \\\n",
    "        supervisor \\\n",
    "        wget && \\\n",
    "        rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "ENV PYTHON_VERSION=3.6\n",
    "RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  && \\\n",
    "    chmod +x ~/miniconda.sh && \\\n",
    "    ~/miniconda.sh -b -p /opt/conda && \\\n",
    "    rm ~/miniconda.sh && \\\n",
    "    /opt/conda/bin/conda create -y --name py$PYTHON_VERSION python=$PYTHON_VERSION && \\\n",
    "    /opt/conda/bin/conda clean -ya\n",
    "ENV PATH /opt/conda/envs/py$PYTHON_VERSION/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH /opt/conda/envs/py$PYTHON_VERSION/lib:/usr/local/cuda/lib64/:$LD_LIBRARY_PATH\n",
    "ENV PYTHONPATH /code/:$PYTHONPATH\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD process_images_from_queue.py /app\n",
    "ADD style_transfer.py /app\n",
    "ADD main.py /app\n",
    "ADD util.py /app\n",
    "ADD requirements.txt /app\n",
    "\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"SCORING_IMAGE\")} scoring_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"SCORING_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Flask App Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our Dockerfile and save it to the directory, `flask_app/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile flask_app/Dockerfile\n",
    "\n",
    "FROM continuumio/miniconda3\n",
    "\n",
    "RUN mkdir /app\n",
    "WORKDIR /app\n",
    "ADD add_images_to_queue.py /app\n",
    "ADD preprocess.py /app\n",
    "ADD postprocess.py /app\n",
    "ADD util.py /app\n",
    "ADD main.py /app\n",
    "\n",
    "# RUN conda install -c anaconda ffmpeg\n",
    "RUN conda install -c conda-forge -y ffmpeg\n",
    "RUN pip install azure\n",
    "RUN pip install flask\n",
    "\n",
    "CMD [\"python\", \"main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker build -t {get_key(env_path, \"FLASK_IMAGE\")} flask_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag and push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"{}/{}\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker tag {get_key(env_path, \"FLASK_IMAGE\")} {repo}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo docker push {repo}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our Flask App and Scoring App deployments on AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to deploy both our aci and aks docker images to the AKS cluster. Since we'll need to set up our gpu and drivers and blobfuse mount point for both deployments, we'll set these up first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_mounts = [\n",
    "    {\"name\": \"nvidia\", \"mountPath\": \"/usr/local/nvidia\"},\n",
    "    {\"name\": \"blob\", \"mountPath\": get_key(env_path, \"MOUNT_DIR\")},\n",
    "]\n",
    "\n",
    "resources = {\n",
    "    \"requests\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "    \"limits\": {\"alpha.kubernetes.io/nvidia-gpu\": 1},\n",
    "}\n",
    "\n",
    "volumes = [\n",
    "    {\"name\": \"nvidia\", \"hostPath\": {\"path\": \"/usr/local/nvidia\"}},\n",
    "    {\n",
    "        \"name\": \"blob\",\n",
    "        \"flexVolume\": {\n",
    "            \"driver\": \"azure/blobfuse\",\n",
    "            \"readOnly\": False,\n",
    "            \"secretRef\": {\"name\": \"blobfusecreds\"},\n",
    "            \"options\": {\n",
    "                \"container\": get_key(env_path, \"STORAGE_CONTAINER_NAME\"),\n",
    "                \"tmppath\": \"/tmp/blobfuse\",\n",
    "                \"mountoptions\": \"--file-cache-timeout-in-seconds=120 --use-https=true\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "env = [\n",
    "    {\n",
    "        \"name\": \"MOUNT_DIR\", \n",
    "        \"value\": get_key(env_path, \"MOUNT_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LB_LIBRARY_PATH\",\n",
    "        \"value\": \"$LD_LIBRARY_PATH:/usr/local/nvidia/lib64:/opt/conda/envs/py3.6/lib\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DP_DISABLE_HEALTHCHECKS\", \n",
    "        \"value\": \"xids\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"STORAGE_MODEL_DIR\",\n",
    "        \"value\": get_key(env_path, \"STORAGE_MODEL_DIR\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SUBSCRIPTION_ID\",\n",
    "        \"value\": get_key(env_path, \"SUBSCRIPTION_ID\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"RESOURCE_GROUP\",\n",
    "        \"value\": get_key(env_path, \"RESOURCE_GROUP\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"REGION\",\n",
    "        \"value\": get_key(env_path, \"REGION\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_NAME\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_NAME\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_SHARED_ACCESS_KEY_VALUE\",\n",
    "        \"value\": get_key(env_path, \"SB_SHARED_ACCESS_KEY_VALUE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_NAMESPACE\",\n",
    "        \"value\": get_key(env_path, \"SB_NAMESPACE\")\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SB_QUEUE\", \n",
    "        \"value\": get_key(env_path, \"SB_QUEUE\")\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the aks deployment and save it to a `scoring_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"scoring-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"dequeue_messages_and_apply_style_transfer\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": int(get_key(env_path, \"NODE_COUNT\")) - 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"scoring-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"scoring-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"SCORING_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 433\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"scoring_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(scoring_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `scoring_app_deployment.json` we created, create our deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create -f scoring_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the flask app deployment and save it to a `flask_app_deployment.json` file using the variables set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flask_app_deployment_json = {\n",
    "    \"apiVersion\": \"apps/v1beta1\",\n",
    "    \"kind\": \"Deployment\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"flask-app\", \n",
    "        \"labels\": {\n",
    "            \"purpose\": \"pre_and_post_processing_and_queue_images\"\n",
    "        }\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"replicas\": 1,\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"labels\": {\n",
    "                    \"app\": \"flask-app\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"flask-app\",\n",
    "                        \"image\": \"{}/{}:latest\".format(get_key(env_path, \"DOCKER_LOGIN\"), get_key(env_path, \"FLASK_IMAGE\")),\n",
    "                        \"volumeMounts\": volume_mounts,\n",
    "                        \"resources\": resources,\n",
    "                        \"ports\": [{\n",
    "                            \"containerPort\": 8080\n",
    "                        }],\n",
    "                        \"env\": env,\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": volumes\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"flask_app_deployment.json\", \"w\") as outfile:\n",
    "    json.dump(flask_app_deployment_json, outfile, indent=4, sort_keys=True)\n",
    "    outfile.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `flask_app_deployment.json` we created, create our flask app deployment on AKS. This can take a few minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl create -f flask_app_deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the state of the pods by running the command: `kubectl get pods`. When the deployment is done, the results may look as follows:\n",
    "```bash\n",
    "NAME                           READY   STATUS              RESTARTS   AGE\n",
    "flask-app-6db66c97ff-x8rq4     1/1     Running             0          78s\n",
    "scoring-app-846dd6bc79-5nm5b   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-6qc6k   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-8gtsv   1/1     Running             0          73s\n",
    "scoring-app-846dd6bc79-hjsfc   1/1     Running             0          73s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expose the flask-app in the kubernetes cluster. This will open a public endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl expose deployment flask-app --type=\"LoadBalancer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `!watch kubectl get services` and wait until the external ip goes from pending to being realized. It can take some time.\n",
    "\n",
    "NOTE: If the following command is run without the external ip being realized, an error will be thrown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_ip = !kubectl get services -o=jsonpath={.items[*].status.loadBalancer.ingress[0].ip}\n",
    "external_ip = external_ip[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll use the `external_ip` later on, save it to the dot-env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_key(env_path, \"AKS_EXTERNAL_IP\", external_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that the deployment works end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the name of the new test video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video_name = \"aks_test_orangutan3.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a copy the old `orangutan.mp4` video but named with the `<new_video_name>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/orangutan.mp4 data/{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `curl` to hit the endpoint of the kubernetes cluster we just deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl {external_ip}\":8080/process?video_name=\"{new_video_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect your kubernetes cluster to see that the process is running. You can use the commands below to do so. Alternatively, you can also inspect the blob storage container to see that the images are being created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Kubectl usage\n",
    "You can use kubectl to perform basic monitoring. Use the following commands:\n",
    "```bash\n",
    "# monitor pods\n",
    "!kubectl get pods\n",
    "\n",
    "# print logs from a pod (<pod-name> can be found when calling 'get pods')\n",
    "!kubectl logs <pod-name>\n",
    "\n",
    "# check all services running on the cluster\n",
    "!kubectl get services\n",
    "\n",
    "# delete a service\n",
    "!kubectl delete services <service-name>\n",
    "\n",
    "# delete a deployment\n",
    "!kubectl delete -f scoring_app_deployment.json\n",
    "!kubectl delete -f flask_app_deployment.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor in kubernetes dashboard\n",
    "You can use the Kubernetes dashboard to monitor the cluster using the following commands:\n",
    "\n",
    "```bash\n",
    "# use the kube_dashboard_access.yaml to create a deployment\n",
    "!kubectl create -f kube_dashboard_access.yaml\n",
    "\n",
    "# use this command to browse\n",
    "!az aks browse -n {get_key(env_path, \"AKS_CLUSTER\")} -g {get_key(env_path, \"RESOURCE_GROUP\")}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional commands for AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale your AKS cluster:\n",
    "\n",
    "```bash \n",
    "!az aks scale \\\n",
    "    --name {get_key(env_path, \"AKS_CLUSTER\")} \\\n",
    "    --resource-group {get_key(env_path, \"RESOURCE_GROUP\")} \\\n",
    "    --node-count 10\n",
    "```\n",
    "\n",
    "Scale your deployment:\n",
    "```bash\n",
    "!kubectl scale deployment.apps/aks-app --replicas=10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to the next [notebook](/notebooks/05_deploy_logic_app.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batchscoringdl]",
   "language": "python",
   "name": "conda-env-batchscoringdl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
